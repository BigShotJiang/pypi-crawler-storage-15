{
  "name": "londonaicentre-llama-serve",
  "version": "1.1.1",
  "summary": "Serve llama models locally",
  "author": null,
  "license": null,
  "home_page": null,
  "download_filename": "londonaicentre_llama_serve-1.1.1.tar.gz",
  "download_time": "2025-12-05T23:51:25.006785",
  "package_url": "https://pypi.org/project/londonaicentre-llama-serve/"
}