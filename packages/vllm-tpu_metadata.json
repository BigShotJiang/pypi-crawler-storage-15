{
  "name": "vllm-tpu",
  "version": "0.12.0",
  "summary": "A high-throughput and memory-efficient inference and serving engine for LLMs",
  "author": "vLLM Team",
  "license": null,
  "home_page": null,
  "download_filename": "vllm_tpu-0.12.0-py3-none-any.whl",
  "download_time": "2025-12-06T07:18:46.321672",
  "package_url": "https://pypi.org/project/vllm-tpu/"
}