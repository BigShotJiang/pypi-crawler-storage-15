{
  "name": "vllm-tpu",
  "version": "0.11.1",
  "summary": "A high-throughput and memory-efficient inference and serving engine for LLMs",
  "author": "vLLM Team",
  "license": null,
  "home_page": null,
  "download_filename": "vllm_tpu-0.11.1-py3-none-any.whl",
  "download_time": "2025-12-03T21:38:46.900531",
  "package_url": "https://pypi.org/project/vllm-tpu/"
}